---
title: An R Markdown document converted from "birds_classification.ipynb"
output: html_document
---

```{r}
library(tree)
library(randomForest)
library(caret)
library(gbm)
library(dplyr)
library(tidyr)
```

```{r}

options(repr.plot.width=20, repr.plot.height=10)
```

For this practical, we will be working with a dataset called `birds.csv`, which was obtained here (https://www.kaggle.com/datasets/zhangjuefei/birds-bones-and-living-habits). This dataset comprises information on 420 birds, each characterized by 10 measurements (features):

- Length and Diameter of the Humerus
- Length and Diameter of the Ulna
- Length and Diameter of the Femur
- Length and Diameter of the Tibiotarsus
- Length and Diameter of the Tarsometatarsus

The goal is to predict the ecological group of each bird, classified as:

- SW: Swimming Birds
- W: Wading Birds
- T: Terrestrial Birds
- R: Raptors
- P: Scansorial Birds
- SO: Singing Birds

Follow these steps for analysis:

1. **Displaying Feature Distribution for Each Ecological Group**
   - Visualize the distribution of each feature across ecological groups.
   - You can choose any visulization that allows you to show all the features (variables) across all ecological groups.
```{r}
birds_data <- read.csv("birds.csv")

features <- c("Humerus_Length", "Humerus_Diameter", "Ulna_Length", "Ulna_Diameter", "Femur_Length", "Femur_Diameter", "Tibiotarsus_Length", "Tibiotarsus_Diameter", "Tarsometatarsus_Length", "Tarsometatarsus_Diameter")

birds_data_long <- birds_data %>%
  select(Type, all_of(features)) %>%
  gather(key = "Feature", value = "Value", -Type)

ggplot(birds_data_long, aes(x = Feature, y = Value, fill = Type)) +
  geom_boxplot() +
  facet_wrap(~Feature, scales = "free_y") +
  theme_minimal() +
  labs(title = "Feature Distribution Across Ecological Groups")
```

2. **Data Preparation**
   - Convert the target column (ecological group) into a categorical variable (factor), as prediction models handle factors, not strings.
   - Identify the number of missing values in each feature using apply to see if any of the variables contain more missing values than others. If that's the case, i.e., a lot of missing values for a single variable, we may have to drop the column. Not that it;s not the case here, so this purely a conceptual exercise.     
   - Remove rows with missing values.
   - Split the data into training and testing sets using the code snippet below:
```{r}
set.seed(123) # for reproducibility
indices <- sample(1:nrow(birds), size = 0.7 * nrow(birds))
train_data <- birds[indices, ]
test_data <- birds[-indices, ]


```
     
3. **Decision Tree Model**
   - Build a decision tree model on the training data.
   - Test the best model on your test data.

5. **Random Forest Model**
   - Choose any number of trees (ntree) and predict accuracy on test data.
     - Pick any value of ntree you deem reasonable
   - Compare results with previou models.

6. **Gradient-Boosted Trees (GBM)**
   - Select parameters for the GBM; you need to inspect the documentation to identify which ones are crucial.
     - Pick any values for those parameters you deem reasonable
   - Display the relative influence of each parameter.
   - Calculate accuracy on test data.

7. **K-Nearest Neighbors (KNN)**
   - Choose a value for `k` (pick any value you deem reasonable) and test the model on test data.


* At the end of this practical, you will explore the caret model and how to use it to train and evaluate machine learning models and select the parameters in a informed way.

